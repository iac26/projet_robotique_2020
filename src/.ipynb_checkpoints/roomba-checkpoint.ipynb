{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-size:40px; font-weight:900;\"> TITRE </div>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Introduction</a></span></li><li><span><a href=\"#Vision\" data-toc-modified-id=\"Vision-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Vision</a></span><ul class=\"toc-item\"><li><span><a href=\"#External-libraries\" data-toc-modified-id=\"External-libraries-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>External libraries</a></span></li><li><span><a href=\"#Color-detection\" data-toc-modified-id=\"Color-detection-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Color detection</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-HSV-color-space\" data-toc-modified-id=\"The-HSV-color-space-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>The HSV color space</a></span></li><li><span><a href=\"#Range-finding-script\" data-toc-modified-id=\"Range-finding-script-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>Range finding script</a></span></li></ul></li><li><span><a href=\"#Polygon-extraction\" data-toc-modified-id=\"Polygon-extraction-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Polygon extraction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Working-principle\" data-toc-modified-id=\"Working-principle-2.3.1\"><span class=\"toc-item-num\">2.3.1&nbsp;&nbsp;</span>Working principle</a></span></li><li><span><a href=\"#Test-script\" data-toc-modified-id=\"Test-script-2.3.2\"><span class=\"toc-item-num\">2.3.2&nbsp;&nbsp;</span>Test script</a></span></li></ul></li><li><span><a href=\"#Robot-detection\" data-toc-modified-id=\"Robot-detection-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Robot detection</a></span><ul class=\"toc-item\"><li><span><a href=\"#Find-the-robot\" data-toc-modified-id=\"Find-the-robot-2.4.1\"><span class=\"toc-item-num\">2.4.1&nbsp;&nbsp;</span>Find the robot</a></span></li><li><span><a href=\"#Position,-orientation-and-scale\" data-toc-modified-id=\"Position,-orientation-and-scale-2.4.2\"><span class=\"toc-item-num\">2.4.2&nbsp;&nbsp;</span>Position, orientation and scale</a></span></li><li><span><a href=\"#The-code\" data-toc-modified-id=\"The-code-2.4.3\"><span class=\"toc-item-num\">2.4.3&nbsp;&nbsp;</span>The code</a></span></li></ul></li><li><span><a href=\"#Obstacles-detection\" data-toc-modified-id=\"Obstacles-detection-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Obstacles detection</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dilatation\" data-toc-modified-id=\"Dilatation-2.5.1\"><span class=\"toc-item-num\">2.5.1&nbsp;&nbsp;</span>Dilatation</a></span></li><li><span><a href=\"#Overlapping-obstacles-merge\" data-toc-modified-id=\"Overlapping-obstacles-merge-2.5.2\"><span class=\"toc-item-num\">2.5.2&nbsp;&nbsp;</span>Overlapping obstacles merge</a></span></li></ul></li><li><span><a href=\"#Code-encapsulation\" data-toc-modified-id=\"Code-encapsulation-2.6\"><span class=\"toc-item-num\">2.6&nbsp;&nbsp;</span>Code encapsulation</a></span></li></ul></li><li><span><a href=\"#Global-navigation\" data-toc-modified-id=\"Global-navigation-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Global navigation</a></span></li><li><span><a href=\"#Filtering\" data-toc-modified-id=\"Filtering-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Filtering</a></span></li><li><span><a href=\"#Local-navigation\" data-toc-modified-id=\"Local-navigation-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Local navigation</a></span></li><li><span><a href=\"#Main-code\" data-toc-modified-id=\"Main-code-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Main code</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## External libraries\n",
    "The purpose of this computer vision module is to provide the robot with information about the world globally surrounding it.\n",
    "\n",
    "The computer vision module must be able to detect:\n",
    "* The robot, it's position and orientation\n",
    "* The obstacles\n",
    "* The objectives\n",
    "* The world scale\n",
    "\n",
    "In order to detect these different objects, we decided to use different colors. And detect color ranges in the image. These colors will then be transformed to shapes. That allows us to extract the contours of obstacles or then centroids of targets. it will also allow us to find the orientation of the robot.\n",
    "\n",
    "We use the OpenCV library. This library requires numpy for it's data types and we also added the matplotlib library to display examples and debug information.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#COLORS \n",
    "RED = (0, 0, 255)\n",
    "GREEN = (0, 255, 0)\n",
    "BLUE = (255, 0, 0)\n",
    "LIGHTBLUE = (255, 127, 0)\n",
    "TURQUOISE = (255, 255, 0)\n",
    "PINK = (255, 0, 255)\n",
    "ORANGE = (0, 127, 255)\n",
    "YELLOW = (0, 255, 255)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Color detection\n",
    "\n",
    "The idea behind our color detection is to define each of our interesting colors as a range of values. When using opneCV's default BGR color space, our colors would need to be defined as a volume in the color space. This is necessary because there are always variations in the color seen by the camera. Find and tunes these volumes in the BGR color space is difficult because BGR is not an intuitive way of describing colors. \n",
    "We decided to use the HSV color space because it is a more \"human intuitive\" representation of the colors.\n",
    "\n",
    "\n",
    "### The HSV color space\n",
    "The HSV color space represents the colors in three dimensions like BGR. But it has a more human intuitive approach as the question of \"which color it is?\" (Hue) can be answered on one dimention. The two others are \"the ammount of coloration\" (Saturation and the \"darkness\" (Value). The HSV color space is a cylindrical coordinates representation of the colors as it is illustrated here:\n",
    "\n",
    "<img src=\"images/hsv_cyl.png\" alt=\"The HSV color space\" width=\"600\"/>\n",
    "\n",
    "In OpenCV, we can easily convert an image to HSV using the color conversion function ```frame = cv2.cvtColor(imag, cv2.COLOR_BGR2HSV)```. The result will be an image with pixels encoded with three values: Hue (between 0 and 179), Saturation and Value (both between 0 and 255).\n",
    "Thanks to this representation we can easily select colors by taking just a \"slice of cylinder\" defined by ```color_low = np.array([h_low, s_low, v_low], dtype=np.uint8)``` and ```color_high = np.array([h_high, s_high, v_high], dtype=np.uint8)```. Such a simple selection volume allows us to use the color selection function ```hsv = cv2.inRange(frame,  color_low, color_high)```. This function will return a mask that is white whenever a pixel is in the range of colors.\n",
    "\n",
    "One of the problems with the HSV color range detection method is that the color is at the 179 -> 0 boundary. so wee need to choose between the yellowish red which is on the 0 side or the pinkish red which is on the 179 part. We decided not to handle the detection for all hues of red as it would add complexity and we can simply use another color :)\n",
    "\n",
    "\n",
    "### Range finding script\n",
    "We wrote a simple range finding script to help us find the color boundaries for different interesting colors.\n",
    "The script simply displays the webcam image with the inRange color mask as overlay. The range can be tuned in real time using sliders. This script allows us to tune the color detection for optimal performance in different ligntning environement and for different colors.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "     \n",
    "\n",
    "cv2.namedWindow(\"Hsv detect\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "cv2.createTrackbar('H low', 'Hsv detect', 0, 179, lambda empty: empty)\n",
    "cv2.createTrackbar('S low', 'Hsv detect', 0, 255, lambda empty: empty)\n",
    "cv2.createTrackbar('V low', 'Hsv detect', 0, 255, lambda empty: empty)\n",
    "\n",
    "cv2.createTrackbar('H high', 'Hsv detect', 0, 179, lambda empty: empty)\n",
    "cv2.createTrackbar('S high', 'Hsv detect', 0, 255, lambda empty: empty)\n",
    "cv2.createTrackbar('V high', 'Hsv detect', 0, 255, lambda empty: empty)\n",
    "\n",
    "cv2.setTrackbarPos('H low', 'Hsv detect', 83)\n",
    "cv2.setTrackbarPos('S low', 'Hsv detect', 165)\n",
    "cv2.setTrackbarPos('V low', 'Hsv detect', 100)\n",
    "\n",
    "cv2.setTrackbarPos('H high', 'Hsv detect', 120)\n",
    "cv2.setTrackbarPos('S high', 'Hsv detect', 255)\n",
    "cv2.setTrackbarPos('V high', 'Hsv detect', 255)\n",
    "\n",
    "while(True):\n",
    "\n",
    "    ret, imag = cap.read()\n",
    "    \n",
    "    frame = cv2.cvtColor(imag, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Trackbars realtime position\n",
    "    h1 = cv2.getTrackbarPos('H low', 'Hsv detect')\n",
    "    s1 = cv2.getTrackbarPos('S low', 'Hsv detect')\n",
    "    v1 = cv2.getTrackbarPos('V low', 'Hsv detect')\n",
    "\n",
    "    h2 = cv2.getTrackbarPos('H high', 'Hsv detect')\n",
    "    s2 = cv2.getTrackbarPos('S high', 'Hsv detect')\n",
    "    v2 = cv2.getTrackbarPos('V high', 'Hsv detect')\n",
    "\n",
    "    color_low = np.array([h1, s1, v1], np.uint8)\n",
    "    color_high = np.array([h2, s2, v2], np.uint8)\n",
    "\n",
    "            \n",
    "    hsv = cv2.inRange(frame,  color_low, color_high)\n",
    "    \n",
    "    hsv_inv = cv2.bitwise_not(hsv)\n",
    "    \n",
    "    blue = np.zeros(frame.shape, np.uint8)\n",
    "\n",
    "    blue[:]=BLUE\n",
    "    \n",
    "    bg = cv2.bitwise_and(imag,imag,mask = hsv_inv)\n",
    "    fg = cv2.bitwise_and(blue,blue,mask = hsv)\n",
    "    \n",
    "    final = cv2.bitwise_or(bg, fg)\n",
    "   \n",
    "    cv2.imshow('Hsv detect', final)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Polygon extraction\n",
    "\n",
    "### Working principle\n",
    "Provided a mask of the colored areas, we need to the borders of the colored areas and transform those borders into simple polygons. \n",
    "\n",
    "This is done using OpenCV's findContours function ```contours, hierarchy = cv2.findContours(hsv, cv2.RETR_EXTERNAL  , cv2.CHAIN_APPROX_SIMPLE)``` The function uses an extended version of the border following algorithm. We configure the function so that it only returns external borders, thus eliminating holes in the mask and an approximation of the borders using as few points as possible. This is done in the function ```def find_color(frame, hsv_low, hsv_high)```\n",
    "\n",
    "Then, we discard the borders that are too small as they are likely to be falsely identified objects. The following condition ```if (cv2.contourArea(cnt) >= AREA_THRESH):``` allows us to keep only the borders big enough.\n",
    "The last step, is to merge the points that are too close together in order to create a low polygon approximation for each object. This is done in the function ```def cleanup_contours(contours, mode=0)```. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanup_contours(contours, mode=0):\n",
    "    #clean contours\n",
    "    AREA_THRESH = 100\n",
    "    MERGE_THRESH = 0.04\n",
    "    EPSILON = 40\n",
    "    \n",
    "    clean_contours = []\n",
    "    \n",
    "    for cnt in contours:\n",
    "        # only take big enough contours\n",
    "        if (cv2.contourArea(cnt) >= AREA_THRESH):\n",
    "            #convex hull\n",
    "            #hull = cv2.convexHull(cnt)\n",
    "            hull = cnt\n",
    "            #lower poly approx\n",
    "            if mode == 0:\n",
    "                epsilon = MERGE_THRESH*cv2.arcLength(hull,True)\n",
    "            else:\n",
    "                epsilon = EPSILON\n",
    "            approx = cv2.approxPolyDP(hull,epsilon,True)\n",
    "            \n",
    "            clean_contours.append(approx)\n",
    "            \n",
    "    return clean_contours\n",
    "\n",
    "\n",
    "def find_color(frame, hsv_low, hsv_high):\n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "\n",
    "    #Using inRange to find the desired range\n",
    "    mask = cv2.inRange(hsv,  hsv_low, hsv_high)\n",
    "    \n",
    "    contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL  , cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    \n",
    "    return cleanup_contours(contours)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test script\n",
    "In order to test the polygon extraction, we use the previously created sript with the polygon detection as addition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "     \n",
    "\n",
    "cv2.namedWindow(\"Hsv detect\", cv2.WINDOW_NORMAL)\n",
    "\n",
    "cv2.createTrackbar('H low', 'Hsv detect', 0, 179, lambda empty: empty)\n",
    "cv2.createTrackbar('S low', 'Hsv detect', 0, 255, lambda empty: empty)\n",
    "cv2.createTrackbar('V low', 'Hsv detect', 0, 255, lambda empty: empty)\n",
    "\n",
    "cv2.createTrackbar('H high', 'Hsv detect', 0, 179, lambda empty: empty)\n",
    "cv2.createTrackbar('S high', 'Hsv detect', 0, 255, lambda empty: empty)\n",
    "cv2.createTrackbar('V high', 'Hsv detect', 0, 255, lambda empty: empty)\n",
    "\n",
    "cv2.setTrackbarPos('H low', 'Hsv detect', 83)\n",
    "cv2.setTrackbarPos('S low', 'Hsv detect', 165)\n",
    "cv2.setTrackbarPos('V low', 'Hsv detect', 100)\n",
    "\n",
    "cv2.setTrackbarPos('H high', 'Hsv detect', 120)\n",
    "cv2.setTrackbarPos('S high', 'Hsv detect', 255)\n",
    "cv2.setTrackbarPos('V high', 'Hsv detect', 255)\n",
    "\n",
    "while(True):\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "    \n",
    "\n",
    "    # Trackbars realtime position\n",
    "    h1 = cv2.getTrackbarPos('H low', 'Hsv detect')\n",
    "    s1 = cv2.getTrackbarPos('S low', 'Hsv detect')\n",
    "    v1 = cv2.getTrackbarPos('V low', 'Hsv detect')\n",
    "\n",
    "    h2 = cv2.getTrackbarPos('H high', 'Hsv detect')\n",
    "    s2 = cv2.getTrackbarPos('S high', 'Hsv detect')\n",
    "    v2 = cv2.getTrackbarPos('V high', 'Hsv detect')\n",
    "\n",
    "    color_low = np.array([h1, s1, v1], np.uint8)\n",
    "    color_high = np.array([h2, s2, v2], np.uint8)\n",
    "\n",
    "            \n",
    "    clean_contours = find_color(frame, color_low, color_high)\n",
    "    \n",
    "    cv2.drawContours(frame, clean_contours, -1, GREEN, 3)\n",
    "    \n",
    "    #draw points\n",
    "    for cnt in clean_contours:\n",
    "        for pt in cnt:\n",
    "            frame = cv2.circle(frame, (pt[0][0], pt[0][1]), radius=5, color=RED, thickness=-1)\n",
    "            \n",
    "    cv2.imshow('Hsv detect', frame)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robot detection\n",
    "In order to simply find the robot's position, we place a blue isosceles triangle on top the the Thymio. The triangle must be facing forward and it's long side must be twice as long as it's short side. \n",
    "\n",
    "### Find the robot\n",
    "\n",
    "![image](images/MR_01.png)\n",
    "\n",
    "The idea for the robot detection is to find every polygon that is a triangle and sort them according to a score, The more the triangle has the right proportions, the lower score it gets. We then use the lowest score as the robot. \n",
    "\n",
    "\n",
    "$$Score = \\frac{||dAB-dCA||^2 + 2\\cdot{}||(dBC - dAB)||^2 + 2\\cdot{}||(dBC - dCA)||^2}{||dAB||^2}$$\n",
    "\n",
    "The score is calculated in python using the norm functions of numpy. ```score = (abs(dAB-dCA)+abs(K*dBC - dAB)+abs(K*dBC - dCA))/np.linalg.norm(dAB)```\n",
    "\n",
    "### Position, orientation and scale\n",
    "From the triangle's summits, we can find the robot's position, orientation and size. The position and orientation will be used for control and the size is used during the initialisation to find the image's scale. The position of the robot is computed as the mean value of the triangle's vertices. \n",
    "The angle is computed from the triangle direction vector using numpy's ```angle = np.arctan2(direction[1], direction[0])``` function. This function calculates the angle of a vector with the arctangeant of it's components while properly handling the singularity at an angle of $\\pi$. \n",
    "\n",
    "### The code\n",
    "The code takes an openCv standart frame as parameter as well as the scale of the world. It returns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calibration\n",
    "BLUE_LOW  = [87, 129, 80]\n",
    "BLUE_HIGH = [131, 255, 255]\n",
    "\n",
    "def detect_robot(frame, scale=1):\n",
    "    blue_low = np.array(BLUE_LOW, np.uint8)\n",
    "    blue_high = np.array(BLUE_HIGH, np.uint8)\n",
    "    frame = frame.copy()\n",
    "    \n",
    "    clean_contours = find_color(frame, blue_low, blue_high)\n",
    "    \n",
    "    good_cnt = []\n",
    "    \n",
    "    for cnt in clean_contours:\n",
    "        if(len(cnt) == 3):\n",
    "            K = 2\n",
    "            A = 0\n",
    "            B = 0\n",
    "            C = 0\n",
    "            dAB = 0\n",
    "            dBC = 0\n",
    "            dCA = 0\n",
    "            p1 = cnt[0][0]\n",
    "            p2 = cnt[1][0]\n",
    "            p3 = cnt[2][0]\n",
    "            d1 = np.linalg.norm(p2-p1)\n",
    "            d2 = np.linalg.norm(p3-p2)\n",
    "            d3 = np.linalg.norm(p1-p3)\n",
    "            min_ix = np.argmin([d1, d2, d3])\n",
    "            if(min_ix == 0):\n",
    "                A = p3\n",
    "                B = p2\n",
    "                C = p1\n",
    "                dAB = d2\n",
    "                dBC = d1\n",
    "                dCA = d3\n",
    "            elif(min_ix == 1):\n",
    "                A = p1\n",
    "                B = p3\n",
    "                C = p2\n",
    "                dAB = d3\n",
    "                dBC = d2\n",
    "                dCA = d1\n",
    "            else:\n",
    "                A = p2\n",
    "                B = p3\n",
    "                C = p1\n",
    "                dAB = d2\n",
    "                dBC = d3\n",
    "                dCA = d1\n",
    "            score = abs(dAB-dCA)+abs(K*dBC - dAB)+abs(K*dBC - dCA)/np.linalg.norm(dAB)\n",
    "            good_cnt.append([A, B, C, score])\n",
    "                       \n",
    "    good_cnt = sorted(good_cnt, key = lambda x: x[3])\n",
    "    \n",
    "    robot_pos = [np.array([0, 0]), 0, False, 0]\n",
    "    \n",
    "    if(len(good_cnt) > 0):\n",
    "        robot_visible = True\n",
    "        A = good_cnt[0][0]\n",
    "        B = good_cnt[0][1]\n",
    "        C = good_cnt[0][2]\n",
    "        D = (np.mean([[B, C]], axis=1))[0]\n",
    "        \n",
    "        \n",
    "        Center = (np.mean([[A, B, C]], axis=1))[0]\n",
    "\n",
    "        direction = A - D\n",
    "        \n",
    "        size = np.linalg.norm(direction)\n",
    "        \n",
    "        angle = np.arctan2(direction[1], direction[0])\n",
    "        \n",
    "        frame = cv2.line(frame, (int(D[0]), int(D[1])), (int(A[0]), int(A[1])), color=BLUE, thickness=1)\n",
    "        frame = cv2.circle(frame, (int(Center[0]), int(Center[1])), radius=5, color=BLUE, thickness=-1)\n",
    "        Center = np.multiply(Center, scale).astype(int)\n",
    "        text =  \"position: ({:0.2f}, {:0.2f}) angle: {:0.4f}\".format(Center[0], Center[1], angle)\n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "        cv2.putText(frame, text, (10, 50), font, 0.5, GREEN, 1, cv2.LINE_AA)\n",
    "        \n",
    "        \n",
    "        robot_pos = [Center, angle, True, size]\n",
    "        \n",
    "    return robot_pos, frame\n",
    "\n",
    "frame = cv2.imread(\"images/colors.png\")\n",
    "\n",
    "pos, image = detect_robot(frame)\n",
    "\n",
    "\n",
    "print(\"Robot position object: [position, angle, visible, size in px]\")\n",
    "print(\"Robot position object:\", pos)\n",
    "    \n",
    "plt.imshow(image[:,:,::-1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obstacles detection\n",
    "The obstacles detection uses the polygon detection algorithm with the addition of the obstacles dilataion.\n",
    "\n",
    "### Dilatation\n",
    "The idea for the second dilatation method is to move the edges of each polygon outwards of a certain ammount to guarantee that the robot does not touch an edge. Additionally, we elongate the moved edges in order to cover part of the corners. Then, we move each vertex outwards to fully conver the corners. All these new verices maake the dilated obstacle.\n",
    "\n",
    "### Overlapping obstacles merge\n",
    "In some cases, after the dilatation, some obstacles that where aalready close might overlap. These overlapping obstacles should be merged into one. \n",
    "\n",
    "In order to do that, we draw the dilated polygons in white onto a black image. Then we run the contour finding alogorithm and openCV will find the merged dilated obstacles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RED_LOW  = [150, 100, 100]\n",
    "RED_HIGH = [179, 255, 255]\n",
    "\n",
    "DIL_COEFF = 100\n",
    "EXP_RATIO = 60\n",
    "\n",
    "def detect_obstacles_alt(frame, scale=1):\n",
    "    frame = frame.copy()\n",
    "    red_low = np.array(RED_LOW, np.uint8)\n",
    "    red_high = np.array(RED_HIGH, np.uint8)\n",
    "    \n",
    "    clean_contours = find_color(frame, red_low, red_high)\n",
    "            \n",
    "    original_contours = []\n",
    "    dil_contour = []\n",
    "    for cnt in clean_contours:\n",
    "        mom = cv2.moments(cnt)\n",
    "        if mom[\"m00\"] != 0:\n",
    "            cx = int(mom[\"m10\"] / mom[\"m00\"])\n",
    "            cy = int(mom[\"m01\"] / mom[\"m00\"])\n",
    "            C = np.array([cx, cy])\n",
    "        else:\n",
    "            C = np.array([0, 0])\n",
    "        ncnt = []\n",
    "        ocnt = []\n",
    "        cnt = list(cnt)\n",
    "        cnt.append(cnt[0])\n",
    "        #print(cnt)\n",
    "        for i, _ in enumerate(cnt[0:-1]):\n",
    "            pt1 = cnt[i][0]\n",
    "            pt2 = cnt[i+1][0]\n",
    "            seg = pt2-pt1\n",
    "            d = seg/np.linalg.norm(seg)\n",
    "            n = np.array([-seg[1], seg[0]])/np.linalg.norm(seg)\n",
    "\n",
    "            N = pt1-C\n",
    "            N = N/np.linalg.norm(N)\n",
    "            npt = (pt1+(DIL_COEFF+EXP_RATIO/2)/scale*N).astype(int)\n",
    "\n",
    "            npt1 = (pt1+DIL_COEFF/scale*n - EXP_RATIO/scale*d).astype(int)\n",
    "            npt2 = (pt2+DIL_COEFF/scale*n + EXP_RATIO/scale*d).astype(int)\n",
    "\n",
    "            #frame = cv2.circle(frame, (npt[0], npt[1]), radius=5, color=(127, 0, 255), thickness=-1)\n",
    "            #frame = cv2.circle(frame, (npt1[0], npt1[1]), radius=5, color=(0, 0, 255), thickness=-1)\n",
    "            #frame = cv2.circle(frame, (npt2[0], npt2[1]), radius=5, color=(0, 127, 255), thickness=-1)\n",
    "\n",
    "            ncnt.append(npt)\n",
    "            ncnt.append(npt1)\n",
    "            ncnt.append(npt2)\n",
    "            ocnt.append(cnt[i][0])\n",
    "        \n",
    "        dil_contour.append(np.array(ncnt))\n",
    "        original_contours.append(np.multiply(ocnt, scale).astype(int))\n",
    "        \n",
    "        \n",
    "    \n",
    "    cv2.drawContours(frame, clean_contours, -1, (0,255,0), 3)\n",
    "    \n",
    "    \n",
    "    black = np.zeros(frame.shape[:2], dtype=np.uint8)\n",
    "    \n",
    "    for i in range(len(dil_contour)):\n",
    "        cv2.drawContours(black, dil_contour, i, (255), -1)\n",
    "\n",
    "    plt.imshow(frame)\n",
    "    \n",
    "    #find contours\n",
    "    \n",
    "    contours, hierarchy = cv2.findContours(black, cv2.RETR_EXTERNAL  , cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    clean_dil_contours = cleanup_contours(contours, 1)\n",
    "    cv2.drawContours(frame, clean_dil_contours, -1, (0,255,0), 3)\n",
    "\n",
    "    scaled_contours = []\n",
    "    for cnt in clean_dil_contours:\n",
    "        ncnt = []\n",
    "        for pt in cnt:\n",
    "            frame = cv2.circle(frame, (pt[0][0], pt[0][1]), radius=5, color=(0, 0, 255), thickness=-1)\n",
    "            ncnt.append(pt[0])\n",
    "        scaled_contours.append(np.multiply(ncnt, scale).astype(int))\n",
    "    \n",
    "    \n",
    "    return scaled_contours, original_contours, frame\n",
    "\n",
    "frame = cv2.imread(\"images/colors.png\")\n",
    "\n",
    "cont, ret, image = detect_obstacles_alt(frame)\n",
    "\n",
    "print(\"Contour object: \", cont)\n",
    "    \n",
    "plt.imshow(image[:,:,::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target detection\n",
    "The target detection uses the polygon detection to fond the conours "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GREEN_LOW  = [41, 64, 0]\n",
    "GREEN_HIGH = [85, 140, 140]\n",
    "def detect_targets(frame, scale=1):\n",
    "    frame = frame.copy()\n",
    "    green_low = np.array(GREEN_LOW, np.uint8)\n",
    "    green_high = np.array(GREEN_HIGH, np.uint8)\n",
    "    \n",
    "    clean_contours = find_color(frame, green_low, green_high)\n",
    "    \n",
    "    centroids = []\n",
    "    \n",
    "    for cnt in clean_contours:\n",
    "        mom = cv2.moments(cnt)\n",
    "        if mom[\"m00\"] != 0:\n",
    "            cx = int(mom[\"m10\"] / mom[\"m00\"])\n",
    "            cy = int(mom[\"m01\"] / mom[\"m00\"])\n",
    "            centroids.append([cx, cy])\n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "        \n",
    "            \n",
    "    cv2.drawContours(frame, clean_contours, -1, (0,255,0), 3)\n",
    "    scaled_centroids = []\n",
    "    \n",
    "    for pt in centroids:\n",
    "        frame = cv2.circle(frame, (pt[0], pt[1]), radius=5, color=(0, 0, 255), thickness=-1)\n",
    "        scaled_centroids.append(np.multiply(pt, scale).astype(int).tolist())\n",
    "        \n",
    "    return scaled_centroids, frame\n",
    "\n",
    "frame = cv2.imread(\"images/colors.png\")\n",
    "\n",
    "targ, image = detect_targets(frame)\n",
    "    \n",
    "print(\"targets object: \", targ)\n",
    "plt.imshow(image[:,:,::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code encapsulation\n",
    "To provide a clean interface for the other modules of the project, the code has been rearranged in a class. This allows us to handle internal global variables in a clean way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entire class?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global navigation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local navigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main code\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "336px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
